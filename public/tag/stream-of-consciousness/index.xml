<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stream of Consciousness on Handmade Oasis</title>
    <link>http://localhost:1313/tag/stream-of-consciousness/</link>
    <description>Recent content in Stream of Consciousness on Handmade Oasis</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <copyright>Copyright Â© 2025, Ramtin Javanmardi.</copyright>
    <lastBuildDate>Sun, 26 Oct 2025 09:37:27 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/tag/stream-of-consciousness/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLMs Are Bottlenecked by Linear Interfaces</title>
      <link>http://localhost:1313/llms-are-bottlenecked-by-linear-interfaces/</link>
      <pubDate>Sun, 26 Oct 2025 09:37:27 +0100</pubDate>
      <guid>http://localhost:1313/llms-are-bottlenecked-by-linear-interfaces/</guid>
      <description>&lt;h2 id=&#34;current-limitation-as-i-see-it&#34;&gt;Current limitation as I see it&lt;/h2&gt;&#xA;&lt;p&gt;So I have been experimenting quite a bit with LLMs recently (see my other posts,&#xA;especially &lt;a href=&#34;http://localhost:1313/state-of-ai-assisted-workflows-october-2025/&#34;&gt;/state-of-ai-assisted-workflows-october-2025/&lt;/a&gt;) and dedicated some&#xA;serious amount of effort to play around with the tech to both learn more but&#xA;also to build an intuition for what it is and what it can do well etc. This has&#xA;led me to having a realisation or an idea, that I&amp;rsquo;m sure is not unique but I have not seen much&#xA;about it being mentioned yet. The idea is that our current LLMs are being&#xA;bottlenecked, leaving performance on the table, by the interfaces we have when&#xA;using them. Mostly our interactions with these models are through a chat&#xA;interface and that forces linearity which also makes context pollution the huge&#xA;problem it currently is.&lt;/p&gt;</description>
    </item>
    <item>
      <title>State of AI Assisted Workflows October 2025</title>
      <link>http://localhost:1313/state-of-ai-assisted-workflows-october-2025/</link>
      <pubDate>Tue, 21 Oct 2025 00:00:00 +0200</pubDate>
      <guid>http://localhost:1313/state-of-ai-assisted-workflows-october-2025/</guid>
      <description>&lt;p&gt;This space is moving at a dizzying pace currently and as such there are&#xA;many new &amp;ldquo;frameworks&amp;rdquo;, methods and approaches popping up and promising the&#xA;world. But having spent the past 2 months trying out many of these on&#xA;non-trivial tasks I have managed to nail a workflow which I have pretty&#xA;good success rate with. This post is intended to be like a context&#xA;compaction of all the things I have explored and learned during this time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI and Software Engineering, the Conflict Within</title>
      <link>http://localhost:1313/ai-and-software-engineering-the-conflict-within/</link>
      <pubDate>Sun, 21 Sep 2025 21:05:43 +0200</pubDate>
      <guid>http://localhost:1313/ai-and-software-engineering-the-conflict-within/</guid>
      <description>&lt;p&gt;I wrote a post a while ago about &lt;a href=&#34;http://localhost:1313/brain-dump-ai-assisted-workflows/&#34;&gt;my current workflow when working with AI&lt;/a&gt;, my&#xA;initial skepticism and some brief mentions of the concept of recreational&#xA;programming. This post is going to be a continuation of the train of thought&#xA;presented in that previous post, but it will be a stand alone piece still. In&#xA;other words there is no need to have read the previous one to follow along in&#xA;this post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Brain Dump: AI Assisted Workflows</title>
      <link>http://localhost:1313/brain-dump-ai-assisted-workflows/</link>
      <pubDate>Thu, 28 Aug 2025 23:15:26 +0200</pubDate>
      <guid>http://localhost:1313/brain-dump-ai-assisted-workflows/</guid>
      <description>&lt;p&gt;This is just like a note or dump of everything I research on AI agents, MCP, and&#xA;other generative AI stuff. I think the correct phrase for it is a stream of&#xA;consciousness dump&lt;/p&gt;&#xA;&lt;p&gt;There seems to be a kind of tier or ladder of sophistication that is slowly&#xA;getting shaped when it comes to AI assisted workflows, especially in relation to&#xA;software engineering. As I see it currently we have the use of online chat&#xA;interfaces, this is where you have chatGPT, Claude and company. At this point 3 years in,&#xA;this I think we have to admit has become table stakes pretty much. The next&#xA;level up is having an agent side by side your daily work. Here you have direct&#xA;access to the LLM and if you use a vscode fork like Cursor or any of their&#xA;competitors its usually just another pane on the right side of your code. This&#xA;is pretty nice, especially when you start to use it. It just feels so nice to&#xA;not have to leave your editor (personally i hated having to use these vs code&#xA;forks, and so glad the next level now exists), and just have the LLM have some&#xA;context around your code and so on.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
